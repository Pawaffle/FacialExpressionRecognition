{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Block 1: Imports and Setup",
   "id": "1ddb754b3d074d95"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T14:56:19.795724Z",
     "start_time": "2025-12-09T14:56:19.792368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "print(\"Libraries loaded.\")"
   ],
   "id": "e9c50997855b24c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded.\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Block 2: Configuration\n",
    "Put your file paths here. This makes it easy to change folders without scrolling through logic code."
   ],
   "id": "3cf41dc3ea892a53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T14:56:19.827390Z",
     "start_time": "2025-12-09T14:56:19.823673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- CONFIGURATION ---\n",
    "\n",
    "# Define your models and their specific input sizes\n",
    "models_config = {\n",
    "    # Replace these paths with your actual .h5 file locations\n",
    "    \"Model_AffectNet\": {\"path\": \"./affectnet_model.keras\", \"size\": 96},\n",
    "    \"Model_FER2013\":   {\"path\": \"./fer2013_model.keras\",   \"size\": 96},\n",
    "    \"Model_CKPlus\":    {\"path\": \"./ckplus_model.keras\",    \"size\": 96},\n",
    "    \"Initial_model\": {\"path\": \"./finetuned_expressdetect_best.keras\", \"size\": 48},\n",
    "}\n",
    "\n",
    "# Define your test datasets paths\n",
    "datasets_config = {\n",
    "    # Replace with the path to the 'test' or 'valid' folder of each dataset\n",
    "    \"Test_AffectNet\": \"./Sorted_data/test\",\n",
    "    \"Test_FER2013\":   \"./fer2013/test\",\n",
    "    \"Test_CKPlus\":    \"./CK_Plus_Ready/test\"\n",
    "}\n",
    "\n",
    "print(\"Configuration defined.\")"
   ],
   "id": "8b39a1c561f92794",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration defined.\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Block 3: The \"Simple\" Evaluator Function\n",
    "This helper function loads the data on-the-fly and runs the standard evaluate command."
   ],
   "id": "ccd7c93f91ebdb87"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T14:56:19.879498Z",
     "start_time": "2025-12-09T14:56:19.875568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "def evaluate_model_on_data(model_path, data_path, img_size):\n",
    "    try:\n",
    "        # A. Load the Model\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "        # B. Load the Dataset (Auto-resized to match the model)\n",
    "        test_data = image_dataset_from_directory(\n",
    "            data_path,\n",
    "            image_size=(img_size, img_size),\n",
    "            batch_size=32,\n",
    "            label_mode='categorical',\n",
    "            shuffle=False, # Standard for testing\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # C. Apply Preprocessing (VGG16 specific)\n",
    "        # Note: If you trained WITHOUT this, comment this line out!\n",
    "        #test_data = test_data.map(lambda x, y: (preprocess_input(x), y))\n",
    "\n",
    "        # D. The \"One-Liner\" Evaluation\n",
    "        # returns [loss, accuracy]\n",
    "        results = model.evaluate(test_data, verbose=0)\n",
    "\n",
    "        return results[1] # Return just the accuracy (e.g., 0.89)\n",
    "\n",
    "    except Exception as e:\n",
    "        # This catches errors like mismatching classes (7 vs 8)\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ],
   "id": "37ef8180fdea51b",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Block 4: Execution & Table\n",
    "This runs the loops and prints your nice 3x3 table."
   ],
   "id": "89f429482b954876"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T14:56:55.518364Z",
     "start_time": "2025-12-09T14:56:19.928093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create an empty table\n",
    "results = pd.DataFrame(index=models_config.keys(), columns=datasets_config.keys())\n",
    "\n",
    "print(\"Starting Evaluation (this may take a minute)...\")\n",
    "\n",
    "for model_name, m_info in models_config.items():\n",
    "    print(f\"\\nEvaluating {model_name}...\", end=\"\")\n",
    "\n",
    "    for data_name, data_path in datasets_config.items():\n",
    "        print(f\"\\n  -> vs {data_name}...\", end=\" \")\n",
    "\n",
    "        accuracy = evaluate_model_on_data(\n",
    "            m_info['path'],\n",
    "            data_path,\n",
    "            m_info['size']\n",
    "        )\n",
    "\n",
    "        if accuracy is not None:\n",
    "            results.loc[model_name, data_name] = f\"{accuracy:.1%}\"\n",
    "            print(f\"Done ({accuracy:.1%})\", end=\"\")\n",
    "        else:\n",
    "            results.loc[model_name, data_name] = \"Error\"\n",
    "            print(\"Failed\", end=\"\")\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*30)\n",
    "print(\"FINAL RESULTS TABLE\")\n",
    "print(\"=\"*30)\n",
    "display(results)"
   ],
   "id": "50d2aef240f6fab8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Evaluation (this may take a minute)...\n",
      "\n",
      "Evaluating Model_AffectNet...\n",
      "  -> vs Test_AffectNet... Done (70.0%)\n",
      "  -> vs Test_FER2013... Done (44.0%)\n",
      "  -> vs Test_CKPlus... Done (84.4%)\n",
      "Evaluating Model_FER2013...\n",
      "  -> vs Test_AffectNet... Done (29.0%)\n",
      "  -> vs Test_FER2013... Done (65.3%)\n",
      "  -> vs Test_CKPlus... Done (82.3%)\n",
      "Evaluating Model_CKPlus...\n",
      "  -> vs Test_AffectNet... Done (26.4%)\n",
      "  -> vs Test_FER2013... Done (29.7%)\n",
      "  -> vs Test_CKPlus... Done (89.6%)\n",
      "Evaluating Initial_model...\n",
      "  -> vs Test_AffectNet... Error: Input 0 of layer \"functional_1\" is incompatible with the layer: expected shape=(None, 96, 96, 3), found shape=(None, 48, 48, 3)\n",
      "Failed\n",
      "  -> vs Test_FER2013... Error: Input 0 of layer \"functional_1\" is incompatible with the layer: expected shape=(None, 96, 96, 3), found shape=(None, 48, 48, 3)\n",
      "Failed\n",
      "  -> vs Test_CKPlus... Error: Input 0 of layer \"functional_1\" is incompatible with the layer: expected shape=(None, 96, 96, 3), found shape=(None, 48, 48, 3)\n",
      "Failed\n",
      "\n",
      "==============================\n",
      "FINAL RESULTS TABLE\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                Test_AffectNet Test_FER2013 Test_CKPlus\n",
       "Model_AffectNet          70.0%        44.0%       84.4%\n",
       "Model_FER2013            29.0%        65.3%       82.3%\n",
       "Model_CKPlus             26.4%        29.7%       89.6%\n",
       "Initial_model            Error        Error       Error"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_AffectNet</th>\n",
       "      <th>Test_FER2013</th>\n",
       "      <th>Test_CKPlus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model_AffectNet</th>\n",
       "      <td>70.0%</td>\n",
       "      <td>44.0%</td>\n",
       "      <td>84.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model_FER2013</th>\n",
       "      <td>29.0%</td>\n",
       "      <td>65.3%</td>\n",
       "      <td>82.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model_CKPlus</th>\n",
       "      <td>26.4%</td>\n",
       "      <td>29.7%</td>\n",
       "      <td>89.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Initial_model</th>\n",
       "      <td>Error</td>\n",
       "      <td>Error</td>\n",
       "      <td>Error</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
