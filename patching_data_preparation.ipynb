{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-10T20:05:10.095333Z",
     "start_time": "2025-11-10T20:05:10.088811Z"
    }
   },
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image\n",
    "from tqdm import tqdm # A library for nice progress bars\n",
    "\n",
    "# --- ⚙️ CONFIGURATION - YOU MUST EDIT THIS! ---\n",
    "\n",
    "# 1. List the full paths to your 4 original image folders (e.g., /mnt/c/...)\n",
    "SOURCE_DIRECTORIES = [\n",
    "    r\"/mnt/c/Users/Pavelishko/Pictures/Хвоя/OriginalSize/kuusi\",\n",
    "    r\"/mnt/c/Users/Pavelishko/Pictures/Хвоя/OriginalSize/mänty\",\n",
    "    r\"/mnt/c/Users/Pavelishko/Pictures/Хвоя/OriginalSize/marjakuusi\",\n",
    "    r\"/mnt/c/Users/Pavelishko/Pictures/Хвоя/OriginalSize/thuja\"\n",
    "]\n",
    "\n",
    "# 2. Set a path for the NEW processed dataset\n",
    "OUTPUT_DIRECTORY = r\"/mnt/c/Users/Pavelishko/Pictures/Хвоя/NewSet_Patches_for_Culling\"\n",
    "\n",
    "# 3. Set the image and split specifications\n",
    "# This now refers to the number of *original high-res images*\n",
    "# that will be used to create patches for each set.\n",
    "SPLITS = {\n",
    "    'train': 104,\n",
    "    'validation': 23,\n",
    "    'test': 23\n",
    "}\n",
    "\n",
    "# 4. Set the Patching parameters\n",
    "PATCH_SIZE = 512  # *2 for manual culling // The dimensions of the square patches (e.g., 1024x1024)\n",
    "OVERLAP = 128    # *2 for manual culling // How much the patches should overlap (in pixels)\n",
    "\n",
    "# ------------------------------------------------\n",
    "\n",
    "# Calculate the step size (how far to move the crop window)\n",
    "# A 1024 patch with 256 overlap means we move 768 pixels for the next patch\n",
    "STEP_SIZE = PATCH_SIZE - OVERLAP\n",
    "\n",
    "# List of file extensions to look for\n",
    "IMAGE_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']\n",
    "\n",
    "print(\"Configuration loaded.\")\n",
    "print(f\"Creating {PATCH_SIZE}x{PATCH_SIZE} patches with a {STEP_SIZE}px step.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded.\n",
      "Creating 512x512 patches with a 384px step.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T20:05:10.151079Z",
     "start_time": "2025-11-10T20:05:10.143328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "\n",
    "def create_and_save_patches(src_path, dest_dir, base_filename, patch_size, step):\n",
    "    \"\"\"\n",
    "    Opens a single source image, crops it into large patches,\n",
    "    RESIZES them to 256x256, and saves them as PNG files.\n",
    "\n",
    "    WARNING: THIS DESTROYS FINE-GRAINED DETAIL.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        patch_counter = 0\n",
    "        final_size = (256, 256) # The final output size you wanted\n",
    "\n",
    "        with Image.open(src_path) as img:\n",
    "            img_width, img_height = img.size\n",
    "\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "\n",
    "            x_coords = list(range(0, img_width - patch_size, step)) + [img_width - patch_size]\n",
    "            y_coords = list(range(0, img_height - patch_size, step)) + [img_height - patch_size]\n",
    "\n",
    "            x_coords = sorted(list(set(x_coords)))\n",
    "            y_coords = sorted(list(set(y_coords)))\n",
    "\n",
    "            for y in y_coords:\n",
    "                for x in x_coords:\n",
    "                    # 1. Crop the large 1020x1020 patch\n",
    "                    box = (x, y, x + patch_size, y + patch_size)\n",
    "                    patch = img.crop(box)\n",
    "\n",
    "                    # 2. NEW LINE: Resize the patch down to 256x256\n",
    "                    patch_resized = patch.resize(final_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "                    patch_filename = f\"{base_filename}__patch_x{x}_y{y}.png\"\n",
    "                    dest_path = os.path.join(dest_dir, patch_filename)\n",
    "\n",
    "                    # 3. MODIFIED LINE: Save the *resized* patch\n",
    "                    patch_resized.save(dest_path, \"PNG\", compress_level=1)\n",
    "\n",
    "                    patch_counter += 1\n",
    "\n",
    "        return (src_path, patch_counter) # Return a tuple to track success\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {src_path}: {e}\")\n",
    "        return (src_path, 0) # Return 0 patches on failure\n",
    "\n",
    "print(\"Patching helper function defined (with CROP and RESIZE).\")"
   ],
   "id": "12054144d2249bf5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patching helper function defined (with CROP and RESIZE).\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T20:06:33.033003Z",
     "start_time": "2025-11-10T20:05:10.198390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Helper function for multiprocessing ---\n",
    "def process_task_wrapper(task_args):\n",
    "    \"\"\"\n",
    "    Helper function to unpack arguments for pool.imap_unordered.\n",
    "    It calls our main patching function.\n",
    "    \"\"\"\n",
    "    return create_and_save_patches(*task_args)\n",
    "# -------------------------------------------\n",
    "\n",
    "\n",
    "print(\"Starting patch dataset creation...\")\n",
    "\n",
    "# --- 1. Build the 'To-Do List' (all tasks) ---\n",
    "tasks = [] # This will be our list of all images to process\n",
    "print(f\"Scanning source directories...\")\n",
    "\n",
    "for source_folder in SOURCE_DIRECTORIES:\n",
    "    class_name = os.path.basename(source_folder)\n",
    "    print(f\"\\nScanning class: {class_name}...\")\n",
    "\n",
    "    # Create the single output directory for this class\n",
    "    # e.g., .../NewSet_Patches_for_Culling/kuusi\n",
    "    dest_dir = os.path.join(OUTPUT_DIRECTORY, class_name)\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "\n",
    "    # Find and filter all images\n",
    "    all_images = []\n",
    "    for f in os.listdir(source_folder):\n",
    "        if any(f.lower().endswith(ext) for ext in IMAGE_EXTENSIONS):\n",
    "            all_images.append(os.path.join(source_folder, f))\n",
    "\n",
    "    print(f\"  Found {len(all_images)} original images to process.\")\n",
    "\n",
    "    # Add ALL images to the main 'tasks' list\n",
    "    for src_path in all_images:\n",
    "        # Use the original image filename as the base for the patch\n",
    "        # e.g., kuusi_148  ->  kuusi_148__patch_x0_y0.png\n",
    "        base_filename = os.path.splitext(os.path.basename(src_path))[0]\n",
    "\n",
    "        # Add the job to our to-do list\n",
    "        task_args = (src_path, dest_dir, base_filename, PATCH_SIZE, STEP_SIZE)\n",
    "        tasks.append(task_args)\n",
    "\n",
    "print(f\"\\n--- Built a 'to-do list' of {len(tasks)} total images. ---\")\n",
    "\n",
    "\n",
    "# --- 2. Execute tasks in parallel (with live progress) ---\n",
    "print(\"Starting parallel processing pool...\")\n",
    "total_patches_generated = 0\n",
    "results = []\n",
    "\n",
    "# Use 'with' to automatically manage the pool\n",
    "# This will use all available CPU cores\n",
    "with multiprocessing.Pool() as pool:\n",
    "\n",
    "    # Use imap_unordered to get results as they finish\n",
    "    # Wrap this with tqdm to create the live progress bar\n",
    "    with tqdm(total=len(tasks), desc=\"Processing images\") as pbar:\n",
    "        # pool.imap_unordered(function_to_call, list_of_arguments)\n",
    "        for result in pool.imap_unordered(process_task_wrapper, tasks):\n",
    "            # As soon as one job is done, 'result' gets its return value\n",
    "            results.append(result)\n",
    "            # Manually update the progress bar\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Process results to get the total count\n",
    "    for src_path, patch_count in results:\n",
    "        if patch_count > 0:\n",
    "            total_patches_generated += patch_count\n",
    "        else:\n",
    "            print(f\"Warning: Failed to process {src_path}\")\n",
    "\n",
    "\n",
    "print(\"\\n\\n✅ Dataset processing complete!\")\n",
    "print(f\"Created a total of {total_patches_generated} patches.\")\n",
    "print(f\"Your new dataset is ready in: {OUTPUT_DIRECTORY}\")\n",
    "print(\"You can now open this folder in ImageGlass or FastStone to start deleting bad patches.\")"
   ],
   "id": "cdebdf541e4d0ea2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting patch dataset creation...\n",
      "Scanning source directories...\n",
      "\n",
      "Scanning class: kuusi...\n",
      "  Found 154 original images to process.\n",
      "\n",
      "Scanning class: mänty...\n",
      "  Found 150 original images to process.\n",
      "\n",
      "Scanning class: marjakuusi...\n",
      "  Found 158 original images to process.\n",
      "\n",
      "Scanning class: thuja...\n",
      "  Found 164 original images to process.\n",
      "\n",
      "--- Built a 'to-do list' of 626 total images. ---\n",
      "Starting parallel processing pool...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 626/626 [01:22<00:00,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "✅ Dataset processing complete!\n",
      "Created a total of 40064 patches.\n",
      "Your new dataset is ready in: /mnt/c/Users/Pavelishko/Pictures/Хвоя/NewSet_Patches_for_Culling\n",
      "You can now open this folder in ImageGlass or FastStone to start deleting bad patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T20:06:33.095869Z",
     "start_time": "2025-11-10T20:06:33.093455Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1e72d7f32100f52b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
